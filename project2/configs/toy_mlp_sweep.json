{ 
  "mlp.init_lr": [
    0.0001 
  ],
  "mlp.num_layers": [
    1,
    4,
    8,
    12,
    24
  ],
  "mlp.hidden_dim": [
      128, 
      256,
      512
  ],
  "mlp.use_bn": [
    true,
    false
  ],
  "main.use_data_augmentation": [
    true,
    false
  ],
  "main.batch_size": [
    512
  ],
  "trainer.max_epochs": [
    100
  ],
  "main.model_name": [
    "mlp"
  ] 

}
